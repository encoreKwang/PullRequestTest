
[자료구조](b15160a2-adf6-43cc-98ea-4fb92e166f29)


# <span style="background-color: #FDEBEC">1. 자료구조</span>


## Array & Linked List


---


### Q. Array는 어떤 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


Array는 연관된 data를 **메모리상에 연속적이며 순차적**으로 **미리 할당된 크기**만큼 저장하는 자료구조 입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 Array에 관한 질문을 할 때에는 매우 높은 확률로 Linked List에 대한 질문도 나오게 됩니다. 따라서 Array의 다양한 특징 중에서 Linked List와 비교가 되는 특성들을 위주로 대답을 하게 되면 편하게 풀어나갈 수 있습니다!   
> Array와 Linked List의 가장 큰 차이점은 메모리에 저장되는 방식과 이에 따른 operation의 연산 속도(time complexity) 입니다. 이를 유념해서 공부해 가시면 좋은 답변을 하실 수 있습니다. 


[배열_2.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a56080aa-1876-4e44-85c6-4491c8b05b12/%E1%84%87%E1%85%A2%E1%84%8B%E1%85%A7%E1%86%AF_2.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122922Z&X-Amz-Expires=3600&X-Amz-Signature=8535de46c544bedc09357489683024556debfc5bc725947fe42a58db376dfcc9&X-Amz-SignedHeaders=host&x-id=GetObject)


### Array의 특징

- 고정된 저장 공간(fixed-size)
- 순차적인 데이터 저장(order)

Array의 장점은 lookup과 append가 빠르다는 것입니다. 따라서 조회를 자주 해야되는 작업에서는 Array 자료구조를 많이 씁니다.


Array의 단점은 fixed-size 특성상 선언시에 Array의 크기를 미리 정해야 된다는 것입니다. 이는 메모리 낭비나 추가적인 overhead가 발생할 수 있습니다.


### 시간복잡도


|              | Array  |
| ------------ | ------ |
| access       | $O(1)$ |
| append       | $O(1)$ |
| 마지막 원소delete | $O(1)$ |
| insertion    | $O(n)$ |
| deletion     | $O(n)$ |
| search       | $O(n)$ |



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q) 미리 예상한 것보다 더 많은 수의 data를 저장하느라 Array의 size를 넘어서게 됐습니다. 이 때, 어떻게 해결할 수 있을까요?


	**[핵심 답변]**


	 기존의 size보다 더 큰 Array를 선언하여 데이터를 옮겨 할당합니다. 모든 데이터를 옮겼다면 기존 Array는 메모리에서 삭제하면 됩니다. 이런식으로 동적으로 배열의 크기를 조절하는 자료구조를 Dynamic array라고 합니다.


	 또 다른 방법으로는, size를 예측하기 쉽지 않다면 Array대신 Linked list를 사용함으로써 데이터가 추가될 때마다 메모리공간을 할당받는 방식을 사용하면 됩니다.



  </details>


---


---


### Q. Dynamic Array는 어떤 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


Array의 경우 size가 고정되었기 때문에 선언시에 설정한 size보다 많은 갯수의 data가 추가되면 저장할 수 없습니다. 이에 반해 Dynamic Array는 저장공간이 가득 차게 되면 resize를 하여 유동적으로 size를 조절하여 데이터를 저장하는 자료구조 입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 Array의 특징중에 fixed-size의 한계점을 보완하고자 고안된 자료구조인 Dynamic Array에 대해서 면접을 위해 깊게 공부하실 내용은 크게 두 가지 입니다.  
> 1. resize를 하는 방식  
> 2. 데이터 추가(append)할 때의 시간복잡도


### Dynamic Array


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_1.png)


Dynamic Array는 size를 자동적으로 resizing을 하는 Array입니다. 기존에 고정된 size를 가진 Static Array의 한계점을 보안하고자 고안되었습니다. Dynamic Array는 data를 계속 추가하다가 기존에 할당된 memory를 초과하게 되면, size를 늘린 배열을 선언하고 그곳으로 모든 데이터를 옮김으로써 늘어난 크기의 size를 가진 배열이 됩니다. 이를 resize라고 합니다. 이로써 새로운 data를 저장할 수 있게 됩니다. 따라서 Dynamic Array는 size를 미리 고민할 필요없다는 장점이 있습니다.


 resizing 을 하는 방법은 여러 가지가 있는데, 대표적으로 기존 Array size의 2배 size를 할당하는 doubling이 있습니다. 


### Doubling


resize의 대표적인 방법으로는 Doubling이 있습니다. 데이터를 추가(append $O(1)$) 하다가 메모리를 초과하게 되면 기존 배열의size보다 두배 큰 배열을 선언하고 데이터를 일일이 옮기는(n개의 데이터를 일일이 옮겨야 하므로 $O(n)$ ) 방법입니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_2.png)


### 분할상환 시간복잡도 Amortized time complexity


Dynamic array에 데이터를 추가할 때마다 $O(1)$의 시간이 걸리게 됩니다. → 추가를 하다가 미리 선언된 size를 넘어서는 순간에 resize를 하게 됩니다. → 이 때는 일일이 데이터를 모두 옮겨야 되기 때문에 이 때만큼은$O(n)$의 시간이 걸리게 됩니다. 


그렇다면 결과적으로 append의 시간복잡도는 $O(1)$일까요 아니면 $O(n)$일까요?


append의 총 과정을 살펴보면 데이터를 마지막 인덱스에 추가하는($O(1)$)작업이 대다수이고, size를 넘어설 때는 size를 두 배 늘리고 데이터를 일일이 옮기는 과정 (resize $O(n)$)이 아주 가끔 발생합니다. 결론부터 말하자면 append의 전체적인 시간복잡도는 $O(1)$입니다. 좀 더 정확히 말하면 **amortized** $O(1)$이라고 부릅니다.


쉽게 설명하자면 가끔 발생하는 O(n)의 resize하는 시간을, 자주 발생하는 O(1)의 작업들이 분담해서 나눠 가짐으로써 전체적으로 O(1)의 시간이 걸린다고 생각하시면 됩니다.



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q) Dynamic Array를 Linked list와 비교하여 장단점을 설명해 주세요.


	**[핵심 답변]**


	Linked List와 비교했을 때, Dynamic Array의 장점은

	- 데이터 접근과 할당이 $O(1)$로 굉장히 빠릅니다. 이는 index 접근하는 방법이 산술적인 연산 [배열 첫 data의 주소값] + [offset]으로 이루어져 있긴 때문입니다. (randam access)
	- Dynamic Array의 맨 뒤에 데이터를 추가하거나 삭제하는 것이 상대적으로 빠릅니다.($O(1)$)

	Linked List와 비교했을 때, Dynamic Array의 단점은

	- Dynamic Array의 맨 끝이 아닌 곳에 data를 insert or remove할 때, 느린 편입니다($O(n)$).  느린 이유는 메모리상에서 연속적으로 데이터들이 저장되어 있기 때문에, 데이터를 추가 삭제할 때 뒤에 있는 data들을 모두 한칸씩 shift 해야되기 때문입니다.
	- resize를 해야할 때, 예상치 못하게 현저히 낮은 performance가 발생합니다.
	- resize에 시간이 많이 걸리므로 필요한 것 이상 memory공간을 할당받습니다. 따라서 사용하지 않고 있는 낭비되는 메모리공간이 발생합니다.


  </details>


---


---


### Q. Linked List에 대해서 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


Linked List는 Node라는 구조체로 이루어져 있는데, Node는 데이터 값과 다음 Node의 address를 저장합니다. Linked List는 물리적인 메모리상에서는 비연속적으로 저장이 되지만 Linked list를 구성하는 각각의 Node가 next Node의 address를 가리킴으로써 논리적인 연속성을 가진 자료구조입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 Linked List는 tree, graph등 다른 자료구조를 구현할 때 자주 쓰이는 기본 자료구조 입니다. 면접에서 Linked list를 설명할 때에는 메모리상에서 불연속적으로 데이터가 저장되는 점과 Node의 next address를 통해 불연속적인 데이터를 연결하여 논리적 연속성을 보장한다는 점을 중심으로 설명하면 됩니다.  
> 또한, 데이터가 추가 되는 시점에서 메모리를 할당하기 때문에 메모리를 좀 더 효율적으로 사용할 수 있다는 장점도 답변으로 구성하면 좋습니다.


### 물리적 메모리 관점에서 본 Linked list - 비연속적


[linked_list.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a2310775-d555-4fd5-b0cd-ba5f263c8dd3/linked_list.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122932Z&X-Amz-Expires=3600&X-Amz-Signature=df15e3ee24461023f18a03565cba52f2b88dd161e7fbac0103fc6e9be0f93bc2&X-Amz-SignedHeaders=host&x-id=GetObject)


### 논리적 연속성


 각 Node들은 next address정보를 가지고 있기 때문에 논리적으로 연속성을 유지하면서 연결되어 있습니다. Array의 경우 연속성을 유지하기 위해 물리적 메모리 상에서 순차적으로 저장하는 방법을 사용하였고, Linked list에는 메모리에서 연속성을 유지하지 않아도 되기 때문에 메모리 사용이 좀 더 자유로운 대신, Next address를 추가적으로 저장해야 하기 때문에 데이터 하나당 차지하는 메모리가 더 커지게 됩니다. 


(1) 그림에서 링크드리스트가 연속적으로 저장된것처럼 보이지만 실제 메모리상에서는 (2)와 같다


(1) 논리적 연속성


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_3.png)


(2) 물리적 불연속성


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_4.png)


### 시간복잡도


Array의 경우 중간에 데이터를 삽입/삭제하게 되면 해당 인덱스의 뒤에 있는 모든 원소들은 shift를 해야만 했습니다. 그러다 보니 $O(n)$의 시간복잡도를 갖게 되었습니다. 하지만 Linked list를 물리적으로 옮길 필요없이 next address가 가리키는 주소값만 변경하면 되기 때문에 $O(1)$의 시간복잡도로 삽입/삭제가 가능합니다.


|           | Linked list |
| --------- | ----------- |
| access    | $O(n)$      |
| search    | $O(n)$      |
| insertion | $O(1)$      |
| deletion  | $O(1)$      |


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_5.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_6.png)



  </details>


---


---


### Q. ⭐ Array vs Linked list를 비교해서 설명해주세요


<details>
  <summary>[핵심 답변]</summary>


Array는 메모리 상에서 연속적으로 데이터를 저장하는 자료구조 입니다. Linked List는 메모리상에서는 연속적이지 않지만, 각각의 원소가 다음 원소의 메모리 주소값을 저장해 놓음으로써 논리적 연속성을 유지합니다.


그래서 각 operation의 시간복잡도가 다릅니다. 데이터 조회는 Array의 경우 $O(1)$, Linked list는 $O(n)$의 시간복잡도를 갖습니다. 삽입/삭제는 Array $O(n)$, Linked list $O(1)$의 시간복잡도를 갖습니다.


따라서 얼마만큼의 데이터를 저장할지 미리 알고있고, 조회를 많이 한다면 Array를 사용하는 것이 좋습니다. 반면에 몇개의 데이터를 저장할 지 불확실하고 삽입 삭제가 잦다면 Linked list를 사용하는 것이 유리합니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡  Array와 Linked List의 주된 차이점들은 메모리 구조에 기인합니다. Array는 메모리상에서 연속적으로 데이터를 저장하고, Linked List는 불연속적으로 저장합니다. 메모리 구조의 차이로 인해 operation구현방법이 다르고 시간복잡도도 다릅니다. 또한 메모리 활용도에서도 차이가 있습니다. 상황에 따라 메모리를 효율적으로 사용할 수 있는 자료구조가 달라집니다. 이를 유념해서 학습을 해봅시다!


### 조회 (lookup)


 Array는 메모리상에서 연속적으로 데이터를 저장하였기 때문에 저장된 데이터에 즉시 접근(random access $O(1)$)할 수 있습니다. 이와 반면 Linked List는 메모리 상에서 불연속적으로 데이터를 저장하기 때문에 순차 접근(Sequential Access)만 가능합니다. 즉, 특정 index의 데이터를 조회하기 위해 $O(n)$의 시간이 걸리게 됩니다.


### 삽입/삭제 (insert/delete)


 Array의 경우 맨 마지막 원소를 추가/삭제하면 시간복잡도가 $O(1)$입니다. 하지만 맨 마지막 원소가 아닌 중간에 있는 원소를 삽입/삭제하면 해당 원소보다 큰 인덱스의 원소들을 한 칸씩 shift 해줘야 하는 비용(cost)이 발생합니다. 따라서 이 경우에는 시간복잡도가 $O(n)$이 됩니다.


 Linked List는 어느 원소를 추가/삭제 하더라도 node에서 다음주소를 가르키는 부분만 다른 주소 값으로 변경하면 되기 때문에 shift할 필요 없어 시간복잡도가 $O(1)$입니다. 


 하지만 Linked list의 경우 추가/삭제를 하려는 index까지 도달하는데 $O(n)$의 시간이 걸리기 때문에, 실질적으로 Linked List도 추가/삭제 시에 $O(n)$의 시간이 걸린다고 볼 수 있습니다.


### memory


 Array의 주된 장점은 데이터 접근과 append가  빠르다는 것입니다. 하지만 메모리 낭비라는 단점이 있습니다. 배열은 선언시에 fixed size를 설정하여 메모리 할당을 합니다. 즉, 데이터가 저장되어 있지 않더라도 메모리를 차지하고 있기 때문에 메모리 낭비가 발생합니다. 


 이와 반면 Linked List는 runtime중에서도 size를 늘리고 줄일 수 있습니다. 그래서 initial size를 고민할 필요 없고, 필요한 만큼 memorry allocation을 하여 메모리 낭비가 없습니다. 



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. 어느 상황에 Linked list를 쓰는게 Array보다 더 나을까요?


	**[핵심 답변]**

	- $O(1)$으로 삽입/삭제를 자주 해야 될 때
	- 얼마만큼의 데이터가 들어올지 예측을 할 수 없을 때
	- 조회 작업을 별로 하지 않을 때

Q. 어느 상황에 Array를 쓰는게 Linked list보다 더 나을까요?


	**[핵심 답변]**

	- 조회 작업을 자주 해야될 때
	- Array를 선언할 당시에 데이터의 갯수를 미리 알고 있을때
	- 데이터를 반복문을 통해서 빠르게 순회할 때.
	- 메모리를 적게 쓰는게 중요한 상황일 때. Linked list보단 Array가 메모리를 적게 차지 하기 때문에 미리 들어올 데이터의 양을 알고만 있다면 Array가 메모리를 더 효율적으로 사용합니다.

Q. Array와 Linked List의 memory allocation은 언제 일어나며, 메모리의 어느 영역을 할당 받나요?


	**[핵심 답변]**


	 Array는 compile 단계에서 memory allocation이 일어납니다. 이를 Static Memory Allocation이라고 합니다. 이 경우 Stack memory영역에 할당됩니다.


	 Linked List의 경우 runtime 단계에서 새로운 node가 추가될 때마다 memory allocation이 일어납니다. 이를 Dynamic Memory Allocation이라고 부릅니다. Heap메모리 영역에 할당됩니다.


	![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_7.png)



  </details>


---


## Queue & Stack


---


### Q. Queue는 무슨 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


queue는 선입선출 FIFO(First In First Out)의 자료구조입니다. 시간복잡도는 enqueue $O(1)$ , dequeue $O(1)$ 입니다.  활용 예시는 Cache구현, 프로세스 관리, 너비우선탐색(BFS) 등이있습니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡  기초적인 자료구조로 면접에서 간단한 질문으로 종종 나오는 문제입니다. LIFO인 stack과 다르게 FIFO자료구조임을 잘 기억하시고 계시면 됩니다. 또한 활용 예시들과 Circular Queue 자료구조를 잘 알고 계시면 면접에서 충분한 답을 하실 수 있습니다.


### FIFO


 queue는 시간 순서상 먼저 집어 넣은 데이터가 먼저 나오는 선입선출 FIFO(First In First Out)형식으로 데이터를 저장하는 자료구조입니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_8.png)


### enqueue & dequeue


queue에서 데이터를 추가하는 것을 enqueue라고 합니다. 


queue에서 데이터를 추출 하는 것은 dequeue라고 합니다. 


enqueue의 경우 queue의 맨 뒤에 데이터를 추가하면 완료되기 때문에 시간복잡도는 O(1) 입니다. 이와 비슷하게 dequeue의 경우 맨 앞의 데이터를 삭제하면 완료 되기 때문에 동일하게 O(1)의 시간복잡도를 갖습니다. 


### 구현 방식


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_9.png)

- Array-Based queue: enqueue와 dequeue 과정에서 남는 메모리가 생깁니다. 따라서 메모리의 낭비를 줄이기 위해 주로 Circular queue형식으로 구현을 합니다.
- List-Based: 재할당이나 메모리 낭비의 걱정을 할 필요가 없어집니다.

### 원형큐(circular queue)


[원형큐.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/00bfb76b-02e1-4dd3-9025-bdd9d43fae8f/%E1%84%8B%E1%85%AF%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%8F%E1%85%B2.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122939Z&X-Amz-Expires=3600&X-Amz-Signature=8d1b4a083a8d746a015e6ec43c40c7e63445ce39028d2de794cb2af6873d31bf&X-Amz-SignedHeaders=host&x-id=GetObject)


### 확장 & 활용


queue의 개념에서 조금 확장한 자료구조들로는 양쪽에서 enqueue와 dequeue가 가능한 deque(double-ended queue)와 시간순서가 아닌 우선순위가 높은 순서로 dequeue할 수 있는 priority queue가 있습니다.


  활용 예시로는 하나의 자원을 공유하는 프린터나, CPU task scheduling, Cache구현, 너비우선탐색(BFS) 등이있습니다. 



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. Array-Base 와 List-Base의 경우 어떤 차이가 있나요?


	**[핵심 답변]**


	 Array-Base의 경우 queue는 circular queue로 구현하는 것이 일반적입니다. 이는 메모리를 효율적으로 사용하기 위함입니다. 또한, enqueue가 계속 발생하면 fixed size를 넘어서게 되기 때문에, dynamic array와 같은 방법으로 Array의 size를 확장시켜야 합니다. 그럼에도 enqueue의 시간복잡도는 (amortized)O(1)를 유지할 수 있습니다.


	 List-Bases의 경우 보통 singly-lilnked list로 구현을 합니다. enqueue는 단순히 singly-lilnked list에서 append를 하는 것으로 구현되고, 이 때 시간복잡도는 O(1)입니다. dequeue는 맨 앞의 원소를 삭제하고 first head를 변경하면 되기 때문에 이 연산도 O(1)의 시간이 걸립니다.


	 요약하자면, 두 가지 종류의 자료구조로 queue를 구현을 하더라도 enqueue와 dequeue는 모두 O(1)의 시간복잡도를 갖습니다. Array-Base의 경우 전반적으로 performance가 더 좋지만, worst case의 경우에는 훨씬 더 느릴 수 있습니다(resize). List-Base의 경우에는 enqueue를 할 때마다 memory allocation을 해야 하기 때문에 전반적인 runtime이 느릴 수 있습니다.



  </details>


---


---


### Q. Stack은 어떤 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


 stack은 후입선출 LIFO(Last In First Out)의 자료구조입니다. 시간복잡도는 push $O(1)$ , pop $O(1)$ 입니다.  활용 예시는 후위 표기법 연산, 괄호 유효성 검사, 웹 브라우저 방문기록(뒤로 가기), 깊이우선탐색(DFS) 등이 있습니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 코딩테스트에서는 stack이 굉장히 중요한 자료구조이지만, 면접에서는 stack을 단독으로 질문하는 경우는 많이 없습니다. 따라서 Queue의 FIFO와 대조되는 LIFO라는 특성과, 활용예시 정도의 기본적인 내용만 이해하고 가시면 충분합니다.


### LIFO


 stack은 시간 순서상 가장 최근에 추가한 데이터가 가장 먼저 나오는 후입선출 LIFO(Last In First Out)형식으로 데이터를 저장하는 자료구조입니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_10.png)


### push & pop


 stack에서 데이터를 추가하는 것을 push라고 하고 데이터를 추출 하는 것은 pop이라고 합니다. push의 경우 stack의 맨 뒤에 데이터를 추가하면 완료되기 때문에 시간복잡도는 O(1)입니다. 이와 동일하게 pop의 경우도 맨 뒤의 데이터를 삭제하면 완료 되기 때문에 O(1)의 시간복잡도를 갖습니다. push와 pop은 모두 stack의 top에 원소를 추가하거나 삭제하는 형식으로 구현됩니다.


[Stack.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9c72def8-4ae2-4a9a-b94b-e51f95b3b6ce/Stack.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122940Z&X-Amz-Expires=3600&X-Amz-Signature=2f769f2065a80074f5b1e0371c30e730e3340ed2bd3780f11a953b634e0ce350&X-Amz-SignedHeaders=host&x-id=GetObject)


### 활용


 stack은 재귀적인 특징이 있어서 프로그램을 개발할 때 자주 쓰이는 자료구조입니다. 활용 예시로는 call stack, 후위 표기법 연산, 괄호 유효성 검사, 웹 브라우저 방문기록(뒤로 가기), 깊이우선탐색(DFS) 등이 있습니다. 



  </details>


---


---


### Q. Stack 두 개를 이용하여 Queue를 구현해 보세요


<details>
  <summary>[면접 </summary>


> 💡 어디서도 배운적은 없지만 의외로 가끔 나와서 당황했던 면접 질문입니다. 따로 준비해 가지 않으면 현장에서 바로 떠올리기 힘들 수 있지만, 한 번만 준비했다면 쉽게 답할 수 있습니다. stack 두 개를 사용하여 enqueue와 dequeue를 구현하는 것에 초점을 맞춰서 문제를 해결하면 됩니다.  
> 사실 이런 문제는 답이 다양하고, 답 자체가 중요하기 보단 답을 찾아가는 과정을 더 중요하게 보기 때문에, 풀이를 외우기보단 접근 방식을 주의깊게 보시길 바랍니다.



  </details>


<details>
  <summary>[핵심 답변]</summary>


queue의 enqueue()를 구현할 때 첫 번째 stack을 사용하고, dequeue()를 구현할 때 두 번째 stack을 사용하면 queue를 구현할 수 있습니다.


편의상 enqueue()에 사용할 stack을 instack이라고 부르고 dequeue()에 사용할 stack을 outstack이라고 칭하겠습니다. 두 개의 stack으로 queue를 구현하는 방법은 다음과 같습니다.

1. enqueue() ::  instack에 push()를 하여 데이터를 저장합니다.
2. dequeue() ::
	1. 만약 outstack이 비어 있다면 instack.pop() 을 하고 outstack.push()를 하여 instack에서 outstack으로 모든 데이터를 옮겨 넣습니다. 이 결과로 가장 먼저 왔던 데이터는 outstack의 top에 위치하게 된다.
	2. outstack.pop()을 하면 가장먼저 왔던 데이터가 가정 먼저 추출된다.(FIFO)

[stack_두개를_이용해서_queue를_구현해보세요.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/39de7141-6272-4b13-8556-9a8b57bc01de/stack_%E1%84%83%E1%85%AE%E1%84%80%E1%85%A2%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A2%E1%84%89%E1%85%A5_queue%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB%E1%84%92%E1%85%A2%E1%84%87%E1%85%A9%E1%84%89%E1%85%A6%E1%84%8B%E1%85%AD.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122941Z&X-Amz-Expires=3600&X-Amz-Signature=ffe8d1cd5ba8e8820f232ee0e644a8b54ae58d9d53687c7ef19ad21575176c6f&X-Amz-SignedHeaders=host&x-id=GetObject)



  </details>


<details>
  <summary>[코드 작성]</summary>


```python
class Queue(object):
    def __init__(self):
        self.instack=[]
        self.outstack=[]

    def enqueue(self,element):
        self.instack.append(element)

    def dequeue(self):
        if not self.outstack:
            while self.instack:
                self.outstack.append(self.instack.pop())
        return self.outstack.pop()
```



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. 시간복잡도는 어떻게 되는지 설명해 주세요.


	**[핵심 답변]**

	- enqueue() : instack.push()를 한번만 하면 되기 때문에 시간복잡도 O(1)입니다.
	- dequeue() : 두 가지 경우를 따져봐야 합니다. worst case는 outstack이 비어있는 경우입니다. 이 때는 instack에 있는 n개의 데이터를 instack.pop()을 한 이후에 outstack.push()를 해줘야 합니다. 따라서 총 2*n 번의 operation이 실행되어야 하므로 O(n)의 시간복잡도를 갖습니다.

		하지만 outstack이 비어있지 않는 경우에는 outstack.pop()만 해주면 됩니다. 이는 O(1)의 시간복잡도를 갖습니다. 이를 종합했을 때, amortized O(1)의 시간복잡도를 갖는다고 할 수 있습니다. 


	enqueue() - O(1)


	dequeue() - O(1)



  </details>


---


---


### Q. Queue 두 개를 이용하여 Stack을 구현해 보세요


<details>
  <summary>[면접 </summary>


> 💡 queue 두 개를 사용하여 stack의 push와 pop를 구현하는 것에 초점을 맞춰서 문제를 해결하면 됩니다. 구현 방법을 외우기보단 문제를 해결해 나가는 과정을 보여주는 것이 좋습니다.



  </details>


<details>
  <summary>[핵심 답변]</summary>


편의상 push()에 사용할 queue는 q1이라고 부르고 pop()에 사용할 queue를 q2라고 칭하겠습니다. 두 개의 queue로 stack을 구현하는 방법은 다음과 같습니다.

1. push() :: q1으로 enqueue()를 하여 데이터를 저장합니다.
2. pop() ::
	1. q1에 저장된 데이터의 갯수가 1 이하로 남을 때까지 dequeue()를 한 후, 추출된 데이터를 q2에 enqueue()합니다. 결과적으로 가장 최근에 들어온 데이터를 제외한 모든 데이터는 q2로 옮겨진다.
	2. q1에 남아 있는 하나의 데이터를 dequeue()해서 가장 최근에 저장된 데이터를 반환한다.(LIFO)
	3. 다음에 진행될 pop()을 위와 같은 알고리즘으로 진행하기 위해 q1과 q2의 이름을 swap한다.

[queue_두개를_이용해서_stack을_구현해보세요.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d6b268ac-3323-4b0a-a267-37dbb8745ca6/queue_%E1%84%83%E1%85%AE%E1%84%80%E1%85%A2%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%8B%E1%85%B5%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A2%E1%84%89%E1%85%A5_stack%E1%84%8B%E1%85%B3%E1%86%AF_%E1%84%80%E1%85%AE%E1%84%92%E1%85%A7%E1%86%AB%E1%84%92%E1%85%A2%E1%84%87%E1%85%A9%E1%84%89%E1%85%A6%E1%84%8B%E1%85%AD.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122945Z&X-Amz-Expires=3600&X-Amz-Signature=96fac169ca340f9e384b220d24ace6b870cb71dc8d403baf17d723abbfc0d63b&X-Amz-SignedHeaders=host&x-id=GetObject)



  </details>


<details>
  <summary>[코드 작성]</summary>


```python
import queue

class Stack(object):
    def __init__(self):
        self.q1 = queue.Queue()
        self.q2 = queue.Queue()

    def push(self, element):
        self.q1.put(element)

    def pop(self):
        while self.q1.qsize() > 1:
            self.q2.put(self.q1.get())

        temp = self.q1
        self.q1 = self.q2
        self.q2 = temp

        return self.q2.get()
```



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. 시간복잡도는 어떻게 되는지 설명해 주세요.


	**[핵심 답변]**

	- push() : q1.enqueue()를 한번만 하면 되기 때문에 $O(1)$의 시간복잡도를 갖습니다.
	- pop() :  q1에 저장되어 있는 n개의 원소중에 n-1개를 q2로 옮겨야 하므로 $O(n)$이 됩니다.


  </details>


---


---


### Q. ⭐ Queue vs priority queue를 비교하여 설명해 주세요


<details>
  <summary>[핵심 답변]</summary>


Queue 자료구조는 시간 순서상 먼저 집어 넣은 데이터가 먼저 나오는 **선입선출 FIFO(First In First Out)** 구조로 저장하는 형식입니다. 이와 다르게 우선순위큐(priority queue)는 들어간 순서에 상관없이 우선순위가 높은 데이터가 먼저 나옵니다. 


Queue의 operation 시간복잡도는 `enqueue` $O(1)$, `dequeue` $O(1)$이고, 


Priority queue는 `push` $O(logn)$ , `pop` $O(logn)$ 입니다. 



  </details>


<details>
  <summary>[면접 </summary>


> 💡 면접질문에서 우선순위큐를 잘 답하기 위해서는 구현 방법과 operation의 시간복잡도를 잘 설명할 수 있어야 합니다.   
> 우선순위큐를 구현하라고 하면 Heap을 구현하시면 됩니다. Heap 자료구조는 이진완전트리를 활용하는 것이고, 대표적인 operation의 시간복잡도는  `push` $O(logn)$ , `pop` $O(logn)$ 입니다. 이 두 가지 특징을 중심으로 공부해 가시면 충분히 답변할 수 있습니다.  
> 또한 tree가 그려져 있는 상태에서 최대힙, 최소힙의 삽입과 삭제시에 어떻게 node가 삭제되고 연결이 변경되는지의 과정을 그려서 설명할 수 있다면 더 좋습니다.


### Heap


Heap은 그 자체로 우선순위큐(priority queue)의 구현과 일치합니다. 


Heap은 완전이진트리 구조입니다. Heap이 되기 위한 조건은 다음과 같습니다.

- 각 node에 저장된 값은 child node들에 저장된 값보다 작거나 같다(min heap)

	⇒ root node에 저장된 값이 가장 작은 값이 된다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_11.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_12.png)


### Heap구현


트리는 보통 Linked list로 구현합니다. 하지만 Heap은 tree임에도 불구하고 array를 기반으로 구현해야 합니다. 그 이유는 새로운  node를 힙의 ‘마지막 위치’에 추가해야 하는데, 이 때 array기반으로 구현해야 이 과정이 수월해지기 때문입니다.

- 구현의 편의를 위해 array의 0번 째 index는 사용하지 않습니다.
- 완전이진트리의 특성을 활용하여 array의 index만으로 부모 자식간의 관계를 정의합니다.
	- $n$번 째 node의 left child node = $2n$
	- $n$번 째 node의 right child node = $2n+1$
	- $n$번 째 node의 parent node = $n/2$

![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_13.png)


### Heap push -  $O(logn)$


heap tree의 높이는 $logN$입니다.


`push()` 를 했을 때, swap하는 과정이 최대  $logN$번 반복되기 때문에 시간복잡도는  $O(logn)$입니다.


[heappush.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fb33b48e-0346-45d2-9233-d4a1a3f4ba6f/heappush.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122953Z&X-Amz-Expires=3600&X-Amz-Signature=0f6941fa1997eeee5a1b26352f38405952aaa2af0afc628a376e0adfc3de47da&X-Amz-SignedHeaders=host&x-id=GetObject)


### Heap pop - $O(logn)$


`pop()`을 했을 때, swap하는 과정이 최대  $logN$번 반복되기 때문에 시간복잡도는  $O(logn)$입니다.

- 각 node에 저장된 값은 child node들에 저장된 값보다 크거나 같다(max heap)

	⇒ root node에 저장된 값이 가장 큰 값이 된다.


[heap.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/af374b4d-726c-4438-a0a6-df042122ffa1/heap.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122953Z&X-Amz-Expires=3600&X-Amz-Signature=e50b9002bfef0ce056e974d0afb0ceaae5f261bfb68bb4c5c6618e683aa6ca2a&X-Amz-SignedHeaders=host&x-id=GetObject)



  </details>


---


## Hash table & BST(Binary Search Tree)


---


### Q. ⭐⭐BST는 어떤 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


이진탐색트리(Binary Search Tree; BST)는 정렬된 tree입니다. 어느 node를 선택하든 해당 node의 left subtree에는 그 node의 값보다 작은 값들을 지닌 node들로만 이루어져 있고, node의 right subtree에는 그 node의 값보다 큰 값들을 지닌 node들로만 이루어져 있는 binary tree입니다.


검색과 저장, 삭제의 시간복잡도는 모두 $O(logn)$이고, worst case는 한쪽으로 치우친 tree가 됐을 때 $O(n)$입니다.



  </details>


<details>
  <summary>[ 면접 </summary>


> 💡 BST는 저장과 동시에 정렬을 하는 자료구조입니다. 따라서 새로운 데이터를 저장할 때 일정한 규칙에 따라 저장을 하게 됩니다. Heap을 공부했었을 때와 마찬가지로, 저장하는 방식을 그림으로 설명할 수 있으면 좋습니다.  
> 이진탐색트리가 되기 위한 조건이 무엇인지, 시간복잡도, worst case, worst case가 발생하지 않게 하기 위해서는 어떻게 해야하는지를 대답할 수 있으면 됩니다.   
> BST는 자주 나오면서 꽤 어려운 자료구조이기 때문에 충분한 학습을 하고 면접을 보러 가시길 바랍니다.


### BST


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_14.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_15.png)


### BST 조건

1. root node의 값보다 작은 값은 left subtree에, 큰 값은 right subtree에 있다.
2. subtree도 1번 조건을 만족한다.(Recursive)

![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_16.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_17.png)


### `search`  $O(logn)$


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_18.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_19.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_20.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_21.png)


[BST3.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0dc3ed9c-42ba-47d7-bd11-f2a5942afdf9/BST3.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T122955Z&X-Amz-Expires=3600&X-Amz-Signature=c2b6f189f30b99437d93204811b0c249a02319f4b506971efbc790a09aabb4f1&X-Amz-SignedHeaders=host&x-id=GetObject)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. 이진트리(Binary tree)는 어떤 자료구조 인가요?


	**[핵심 답변]**


	모든 node의 child nodes의 갯수가 2 이하인 트리를 이진 트리라고 합니다.


Q. BST의 worst case 시간복잡도는  $O(n)$입니다. 어떠한 경우에 worst case가 발생하나요? 


	**[핵심 답변]**


	균형이 많이 깨져서 한 쪽으로 치우친 BST의 경우에 worst case가 됩니다. 이렇게 되면 Linked list와 다를게 없어집니다. 따라서 탐색시에 $O(logn)$이 아니라 $O(n)$이 됩니다.


	![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_22.png)


Q. 해결방법은 무엇인가요


	**[핵심 답변]**


	자가 균형 이진 탐색 트리(Self-Balancing BST)는 알고리즘으로 이진 트리의 균형이 잘 맞도록 유지하여 높이를 가능한 낮게 유지합니다. 대표적으로 AVL트리와 Red-black tree가 있습니다. JAVA에서는 hashmap의 seperate chaning으로써 Linked list와 Red-black tree를 병행하여 저장합니다.



  </details>


---


---


### Q. ⭐⭐ Hash table는 어떤 자료구조 인가요?


<details>
  <summary>[핵심 답변]</summary>


hash table은 <span style="background-color: #FBF3DB">효율적인 탐색(빠른 탐색)</span>을 위한 자료구조로써 key-value쌍의 데이터를 입력받습니다. hash function $h$에 key값을 입력으로 넣어 얻은 해시값 $h(k)$를 위치로 지정하여 key- value 데이터 쌍을 저장합니다. 저장, 삭제, 검색의 시간복잡도는 모두 $O(1)$입니다. 



  </details>


<details>
  <summary>[면접 </summary>


> 💡 cs 면접에서 가장 자주 나오는 질문중에 하나입니다. hashtable이 면접 단골질문인 이유는 다음과 같습니다.  
> 1. 실무에서도 활용도가 높은 자료구조입니다.  
> 2. Linked list, Array 더 나아가면 Tree까지 질문할 수 있습니다.  
> 3. 시간복잡도에 대해서 물어보기 좋습니다.  
>   
>  한편, 좋은 hash function의 조건을 물어보는 경우도 있습니다. 좋은 hash function의 핵심적인 조건은 해시값이 고르게 분포되게 하는 것입니다.


### Direct-address Table


Direct-address Table(직접 주소화 테이블)이란, key 값으로 k를 갖는 원소는 index k에 저장하는 방식입니다. 


```text
key: 출석번호, value: 이름

(3, 노정호)
(5, 배준석)
(6, 정재헌)
(7, 남영욱)
```


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_23.png)


직접 주소화 방법으로 통해 key-value 쌍의 데이터를 저장하고자 하면 많은 문제가 발생합니다.

- 불필요한 공간 낭비

```text
key: 학번, value: 이름

(2022390, 노정호)
(2022392, 배준석)
(2022393, 정재헌)
(2022401, 남영욱)
```


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_24.png)

- key가 다양한 자료형을 담을 수 없게 됨

```text
key: ID, value: 이름

(nossi8128, 노정호)
(js9876, 배준석)
(zebra001, 정재헌)
(nam1234, 남영욱)
```


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_25.png)


### Hash table


 (key, value) 데이터 쌍을 저장하기 위한 방법으로 직접 주소화 방법이 잘 맞지않습니다. hash table은 hash function $h$를 이용해서 ($key$, $value$)를 index: $h(k)$에 저장합니다. 이 때, <span style="background-color: #FBECDD">“키</span> $k$<span style="background-color: #FBECDD">값을 갖는 원소가 위치</span> $h(k)$<span style="background-color: #FBECDD">에 hash된다.” 또는 “</span>$h(k)$<span style="background-color: #FBECDD">는 키</span> $k$<span style="background-color: #FBECDD">의 해시값이다”</span>라고 표현합니다. key는 무조건 존재해야 하며, 중복되는 key가 있어서는 안됩니다.


 한편, hash table을 구성하고 있는, (key, value)데이터를 저장할 수 있는 각각의 공간을 slot 또는 bucket이라고 합니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_26.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_27.png)


### Collision


collision이란 서로 다른 key의 해시값이 똑같을 때를 말합니다. 즉, 중복되는 key는 없지만 해시값은 중복될 수 있는데 이 때 collision이 발생했다고 합니다. 따라서 collision이 최대한 적게 나도록 hash function을 잘 설계해야하고, 어쩔 수 없이 collision이 발생하는 경우 seperate chaining 또는 open addressing등의 방법을 사용하여 해결합니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_28.png)


### 시간복잡도와 공간효율


**시간복잡도**는 저장, 삭제, 검색 모두 기본적으로 $O(1)$이지만, collision으로 인하여 최악의 경우  $O(n)$이 될 수 있습니다. 


**공간효율성**은 떨어집니다. 데이터가 저장되기 전에 미리 저장공간(slot, bucket)을 확보해야 하기 때문입니다. 따라서 저장공간이 부족하거나 채워지지 않은 부분이 많은 경우가 생길 수 있습니다.



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. 좋은 hash function의 조건은 뭘까요?


	**[핵심 답변]** 


	각 상황마다 good hash function은 달라질 수 있으나 대략적인 기준은 연산 속도가 빨라야 하고, 해시값이 최대한 겹치지 않아야 합니다.



  </details>


---


---


### Q. ⭐⭐⭐⭐ Hash table에서 collision이 발생하면 어떻게 되나요? 해결방법엔 뭐가 있을까요?


<details>
  <summary>[핵심 답변]</summary>


collision이 발생할 경우 대표적으로 2가지 방법으로 해결합니다.


첫 번째, open addressing 방식은 collision이 발생하면 미리 정한 규칙에 따라 hash table의 비어있는 slot을 찾습니다. 빈 slot을 찾는 방법에 따라 크게 Linear Probing, Quadratic Probing, Double Hashing으로 나뉩니다.


두 번째, separete chaining 방식은 linked list를 이용합니다. 만약에 collision이 발생하면 linked list에 노드(slot)를 추가하여 데이터를 저장합니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡  정말 자주나오고 중요한 면접 질문입니다. 꼭 철저하게 준비해가시길 추천드립니다. hashtable에서 collision이 발생했을 때, seperate chaining과 open addressing 두 가지 방식으로 해결을 합니다. 두 가지 방법이 어떤 메커니즘으로 작동하는지, 어떤 차이점이 있는지를 잘 학습하고 가시기 바랍니다.  
>  또한 seperate chaining의 경우 worst case의 시간복잡도에 대해서 설명할 줄 알아야 합니다. 삽입과 검색, 삭제의 시간복잡도는 $O(1)$이지만, worst case의 경우에 $O(n)$가 될 수 있습니다. 왜 $O(n)$이 되는지를 설명할 수 있도록 collision에 대해서 같이 살펴보도록 할게요!


### Open addressing


 open addressing 방식은 collision이 발생하면 미리 정한 규칙에 따라 hash table의 비어있는 slot을 찾습니다. 추가적인 메모리를 사용하지 않으므로 linked list 또는 tree자료구조를 통해 추가로 메모리 할당을 하는 separate chaining방식에 비해 메모리를 적게 사용합니다.


 open addressing은 빈 slot을 찾는 방법에 따라 크게 Linear Probing, Quadratic Probing, Double Hashing으로 나뉩니다.

- Linear Probing(선형 조사법)& Quadratic Probing(이차 조사법) : 선형 조사법은 충돌이 발생한 해시값으로 부터 일정한 값만큼$(+1, +2, +3, ...)$ 건너 뛰어, 비어 있는 slot에 데이터를 저장합니다. 이차 조사법은 제곱수($+1^2, +2^2, +3^2, ...$)로 건너 뛰어, 비어 있는 slot을 찾습니다.

	 충돌이 여러번 발생하면 여러번 건너 뛰어 빈 slot을 찾습니다. 선형 조사법과 이차 조사법의 경우 충돌 횟수가 많아지면 특정 영역에 데이터가 집중적으로 몰리는 클러스터링(clustering)현상이 발생하는 단점이 있습니다. 클러스터링 현상이 발생하면, 평균 탐색 시간이 증가하게 됩니다.

- Double Hashing(이중해시, 중복해시) : 이중 해싱은 open addressing 방식을 통해 collision을 해결할 때, probing하는 방식중에 하나입니다. linear probing이나 quadratic probing을 통해 탐사할 때는 탐사이동폭이 같기 때문에 클러스터링 문제가 발생할 수 있습니다. 클러스터링 문제가 발생하지 않도록 2개의 해시함수를 사용하는 방식을 이중 해싱이라고 합니다. 하나는 최초의 해시값을 얻을 때 사용하고 또 다른 하나는 해시 충돌이 발생할 때 탐사 이동폭을 얻기 위해 사용합니다.

[Hash_table에서_collision이_발생하면_어떻게_되나요.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c47d9648-9f7b-462c-9eaf-9569cf1e7a94/Hash_table%E1%84%8B%E1%85%A6%E1%84%89%E1%85%A5_collision%E1%84%8B%E1%85%B5_%E1%84%87%E1%85%A1%E1%86%AF%E1%84%89%E1%85%A2%E1%86%BC%E1%84%92%E1%85%A1%E1%84%86%E1%85%A7%E1%86%AB_%E1%84%8B%E1%85%A5%E1%84%84%E1%85%A5%E1%87%82%E1%84%80%E1%85%A6_%E1%84%83%E1%85%AC%E1%84%82%E1%85%A1%E1%84%8B%E1%85%AD.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T123001Z&X-Amz-Expires=3600&X-Amz-Signature=b051d7d6d65467f86df6b398778de47f64ac1cccfe130d98b6518a0676fb8b9a&X-Amz-SignedHeaders=host&x-id=GetObject)


### Separate chaining


Separate chaining 방식은 linked list(또는 Tree)를 이용하여 collision을 해결합니다. 충돌이 발생하면 linked list에 노드(slot)를 추가하여 데이터를 저장합니다.

- 삽입: 서로 다른 두 key가 같은 해시값을 갖게 되면 linked list에 node를 추가하여 (key, value) 데이터 쌍을 저장합니다. 삽입의 시간복잡도는 $O(1)$입니다.
- 검색: 기본적으로  $O(1)$의 시간복잡도 이지만 <u>**최악의 경우**</u> $O(n)$의 시간복잡도를 갖습니다.
- 삭제:  삭제를 하기 위해선 검색을 먼저 해야하므로 검색의 시간복잡도와 동일합니다. 기본적으로 $O(1)$이지만 <u>**최악의 경우**</u> $O(n)$의 시간복잡도를 갖습니다.

 <span style="background-color: #FBECDD">worst case의 경우 n개의 모든 key가 동일한 해시값을 갖게 되면 길이 n의 linked list가 생성되게 됩니다. 이 때, 검색의 시간복잡도가</span> $O(n)$<span style="background-color: #FBECDD">이 됩니다.</span>


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_29.png)


⁉️참고: seperate chaining은 기본적으로 linked list를 이용하여  데이터를 저장하지만, collision이 많이 발생하여 linked list의 길이가 길어지면 Binary Search Tree(BST)자료구조를 이용하여 데이터를 저장하기도 합니다. BST를 사용함으로써 검색의 worst case 시간복잡도를 $O(n)$ 에서 $O(logn)$으로 낮출 수 있습니다.



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. worst case에 시간복잡도는 $O(n)$이라고 했는데 어떤 상황인가요?


	**[핵심 답변]**


	n개의 모든 key가 동일한 해시값을 갖게 되면 길이 n의 linked list가 생성되게 됩니다. 이 때, 특정 key를 찾기 위해서는 길이 n의 linked list를 검색하는 $O(n)$의 시간복잡도와 동일하게 됩니다.


Q. 이중해싱(double hashing)이 무엇인지 설명해 주세요.


	**[핵심 답변]**


	이중 해싱은 open addressing 방식을 통해 collision을 해결할 때, probing하는 방식중에 하나입니다. linear probing이나 quadratic probing을 통해 탐사할 때는 탐사이동폭이 같기 때문에 클러스터링 문제가 발생할 수 있습니다. 클러스터링 문제가 발생하지 않도록 2개의 해시함수를 사용하는 방식을 이중 해싱이라고 합니다. 하나는 최초의 해시값을 얻을 때 사용하고 또 다른 하나는 해시 충돌이 발생할 때 탐사 이동폭을 얻기 위해 사용합니다.



  </details>


---


$$
lim_{n \to \infty} \int_{-N}^{N} e^x\, dx + \oint_{C} x^3\, dx + 4y^2\, dy
$$


$$
{n}\mathrm{P}{k} ,{n}\mathrm{C}{k} , {n}\mathrm{\Pi}{k},{n}\mathrm{H}{k}, P(n,k), S(n,k),\mathrm{P}_{k}^{n}
$$


$$
\begin{matrix}
f(n+1) &=& (n+1)^2 \\ &=& n^2 + 2n + 1
\end{matrix}
$$


[운영체제](ac614a10-420a-4fcd-8839-89e5dc39598a)


# 2. 운영체제 (OS)


## Process & Thread


---


### Q. process를 간단히 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


실행파일(program)이 memory에 적재되어 CPU를 할당받아 실행되는 것을 process라고 합니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 운영체제를 관통하는 핵심적인 단어 하나를 뽑는다면 그건 바로 process에요. 운영체제가 작동하는 다양한 원리들이 바로 process를 위해 존재하는 것입니다. 따라서 process의 정의를 잘 이해한다면 앞으로 나올 내용들도 자연스럽게 이해가 가실 거에요!  
> process를 memory와 CPU관점으로 면접관에게 설명을 하시면 됩니다.


### Process


프로세스(process)란 실행중인 프로그램(program in execution)을 뜻합니다. 즉, 실행파일 형태로 존재하던 program이 memory에 적재되어 CPU에 의해 실행(연산)되는 것을 process라고 합니다.


(+ program은 단순히 명령어 리스트를 포함하는 파일입니다.)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_30.png)


### Memory에 적재


memory는 CPU가 직접 접근할 수 있는 컴퓨터 내부의 기억장치 입니다. program이 CPU에서 실행되려면 해당 내용이 memory에 적재된 상태여야만 합니다.


프로세스에 할당되는 memory 공간은 Code, Data, Stack, Heap 4개의 영역으로 이루어져 있으며, 각 process마다 독립적으로 할당을 받습니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_31.png)


| Code 영역  | 실행한 프로그램의 코드가 저장되는 메모리 영역                   |
| -------- | ------------------------------------------- |
| Data 영역  | 프로그램의 전역 변수와 static 변수가 저장되는 메모리 영역         |
| Heap 영역  | 프로그래머가 직접 공간을 할당(malloc)/해제(free) 하는 메모리 영역 |
| Stack 영역 | 함수 호출 시 생성되는 지역 변수와 매개 변수가 저장되는 임시 메모리 영역   |


### CPU의 연산과 PC register


프로그램의 코드를 토대로 CPU가 실제로 연산을 해야만 프로그램이 실행된다고 볼 수 있습니다. 그럼 어떤 코드를 읽어야 하는가를 정하는 것은 CPU 내부에 있는 PC(Program counter) register에 저장되어 있습니다. PC register에는 다음에 실행될 코드(명령어, instruction)의 주소값이 저장되어 있습니다. 즉, memory에 적재되어있는 process code영역의 명령어중 다음번 연산에서 읽어야할 명령어의 주소값을 PC register가 순차적으로 가리키게 되고, 해당 명령어를 읽어와서 CPU가 연산을 하게 되면 process가 실행이 되는 것입니다.



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. process의 memory영역(code, data, stack, heap)에 대해서 설명해 주세요.


	**[핵심 답변]**


	프로세스가 운영체제에서 할당받는 메모리 공간은 code, data, stack, heap 영역으로 구분됩니다.

	- code 영역은 실행한 프로그램의 코드가 저장되는 메모리 영역입니다.
	- data 영역은 프로그램의 전역 변수와 static 변수가 저장되는 메모리 영역입니다.
	- heap 영역은 프로그래머가 직접 공간을 할당(malloc)/해제(free) 하는 메모리 영역입니다.
	- stack 영역은 함수 호출 시 생성되는 지역 변수와 매개 변수가 저장되는 임시 메모리 영역입니다.


  </details>


---


---


### Q. ⭐⭐⭐⭐ Multi process에 대해서 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


Multi process란 2개 이상의 process가 동시에 실행되는 것을 말합니다. 동시에라는 말은 동시성(concurrency)과 병렬성(parallelism) 두 가지를 의미합니다. 


동시성은 CPU core가 1개일 때, 여러 process를 짧은 시간동안 번갈아 가면서 연산을 하게 되는 시분할 시스템(time sharing system)으로 실행되는 것입니다.


병렬성은 CPU core가 여러개일 때, 각각의 core가 각각의 process를 연산함으로써 process가 동시에 실행되는 것입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 요새 우리가 쓰는 노트북은 CPU core가 여러개 있죠. core가 여러개여서 실제로 여러 process가 동시에 처리되는 것을 병렬성 이라고 합니다. 하지만 면접에서는 병렬성에 대한 깊은 질문은 거의 나오지 않아요. 다만 병렬성이 어떤 뜻인지 정도만 이해하고 넘어가시면 됩니다.  
> 면접에서 병렬성보다 훨씬 중요한 것은 동시성이에요. 한 개의 CPU core는 당연히 한번에 하나의 연산밖에 못합니다. 그런데 도대체 어떻게 동시에 여러 process를 처리할까요? 정답은 동시성입니다. 동시성을 통해 multi process가 작동되는 원리를 잘 이해하시면 됩니다.  
> 면접에서는 시분할 시스템을 시작으로 context, PCB, context switcing, process의 memory영역을 설명하시면 완벽한 답변이 될거에요.


### 동시성(Concurrency) vs 병렬성(Parallelism)


| 동시성                | 병렬성                   |
| ------------------ | --------------------- |
| Single core        | Multi core            |
| 동시에 실행되는 것 같아 보인다. | 실제로 동시에 여러 작업이 처리 된다. |


앞으로 설명할 모든 내용은 Single core의 <span style="background-color: #F4F0F7CC">동시성</span>에 초점을 맞춰져 있습니다.


[11111.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a1e95d9d-ea37-4f80-8783-6c9ee3ef242d/11111.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T123011Z&X-Amz-Expires=3600&X-Amz-Signature=26c1870045f29fd9ceb4a8ebaeb99dab09ef85f65fd7e67a063c6d2929787790&X-Amz-SignedHeaders=host&x-id=GetObject)


### Multi process


Multi process란 2개 이상의 process가 동시에 실행되는 것을 말합니다. 이 때 process들은 CPU와 메모리를 공유하게 됩니다. 


memory의 경우에는 여러 process들이 각자의 memory영역을 차지하여 동시에 적재됩니다.


반면 하나의 CPU는 매 순간 하나의 process만 연산할 수 있습니다. 하지만 CPU의 처리 속도가 워낙 빨라서 수 ms 이내의 짧은 시간동안 여러 process들이 CPU에서 번갈아 실행되기 때문에 사용자 입장에서는 여러 프로그램이 동시에 실행되는 것처럼 보입니다. 이처럼 CPU의 작업시간을 여러 process들이 조금씩 나누어 쓰는 시스템을 시분할 시스템(time sharing system)이라고 부릅니다.


### 메모리관리


여러 process가 동시에 memory에 적재된 경우, 서로 다른 process의 영역을 침범하지 않도록 각 process가 자신의 memory영역에만 접근하도록 운영체제가 관리해줍니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_32.png)


### CPU의 연산과 PC register


CPU는 PC(Program counter) register가 가리키고 있는 명령어를 읽어들여 연산을 진행합니다. PC register에는 다음에 실행될 명령어의 주소값이 저장되어 있습니다. multi process시스템에서는 process1이 진행되고 있을 때는 process1의 code 영역을 PC register가 가리키다가, process2가 진행되면 process2의 code 영역을 가리키게 됩니다. CPU는 PC register가 가리키는 곳에 따라 process를 변경해 가면서 명령어를 읽어들이고 연산을 하게 됩니다.


[44444.m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fa3c2916-e9da-4f92-b65c-6c28cf2961cb/44444.m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T123011Z&X-Amz-Expires=3600&X-Amz-Signature=7ce6a45bba4a0028bcc138d8210ed30dfdf92c95a0af52d63591a3743de06870&X-Amz-SignedHeaders=host&x-id=GetObject)


### Context


시분할 시스템에서는 한 process가 매우 짧은 시간동안 CPU를 점유하여 일정부분의 명령을 수행하고, 다른 process에게 넘깁니다. 그 후 차례가 되면 다시 CPU를 점유하여 명령을 수행합니다. 따라서 이전에 어디까지 명령을 수행했고, register에는 어떤 값이 저장되어 있었는지에 대한 정보가 필요하게 됩니다. process가 현재 어떤 상태로 수행되고 있는지에 대한 총체적인 정보가 바로 context입니다. context 정보들은 PCB(Process Control Block)에 저장을 합니다.


### PCB(Process Control Block)


PCB는 운영 체제가 프로세스를 표현한 자료구조 입니다. PCB에는 프로세스의 중요한 정보가 포함되어 있기 때문에, 일반 사용자가 접근하지 못하도록 보호된 메모리 영역 안에 저장이 됩니다. 일부 운영 체제에서 PCB는 커널 스택에 위치합니다. 이 메모리 영역은 보호를 받으면서도 비교적 접근하기가 편리하기 때문입니다.


PCB에는 일반적으로 다음과 같은 정보가 포함됩니다.


| PCB                 |                                                              |
| ------------------- | ------------------------------------------------------------ |
| Process State       | new, running, waiting, halted 등의 state가 있다.                  |
| Process Number      | 해당 process의 number                                           |
| Program counter(PC) | 해당 process가 다음에 실행할 명령어의 주소를 가리킨다                            |
| Registers           | 컴퓨터 구조에 따라 다양한 수와 유형을 가진 register 값들                         |
| Memory limits       | base register, limit register, page table 또는 segment table 등 |
| ...                 |                                                              |


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_33.png)


### Context switch


Context switch란 한 프로세스에서 다른 프로세스로 **CPU 제어권을 넘겨**주는 것을 말합니다.


이 때 이전의 프로세스의 상태를 **PCB에 저장하여 보관**하고 새로운 프로세스의 **PCB를 읽어서 보관된 상태를 복구**하는 작업이 이루어집니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_34.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. process의 context는 무엇인가요?


	**[핵심 답변]**


	context란 process가 현재 어떤 상태로 수행되고 있는지에 대한 정보입니다. 해당 정보는 PCB(Process Control Block)에 저장을 합니다.


Q. PCB(Process Control Block)에 저장되는 것들은 무엇이 있나요?


	**[핵심 답변]**


	PCB는 운영체제가 process에 대해 필요한 정보를 모아놓은 자료구조입니다. PCB에는 일반적으로 다음과 같은 정보가 포함됩니다.

	- Process number
	- Process state
	- Program Counter (PC), 레지스터
	- CPU 스케쥴링 정보, 우선순위
	- 메모리 정보 (해당 process의 주소 공간 등)

Q. Context switch에 대해서 설명해 주세요.


	**[핵심 답변]**


	Context switch란 한 프로세스에서 다른 프로세스로 **CPU 제어권을 넘겨**주는 것을 말합니다.


	이 때 이전의 프로세스의 상태를 **PCB에 저장하여 보관**하고 새로운 프로세스의 **PCB를 읽어서 보관된 상태를 복구**하는 작업이 이루어집니다.


Q. process의 state에는 어떤 것들이 있나요?


	**[핵심 답변]**


	프로세스는 **실행**(running), **준비**(ready), **봉쇄**(wait, sleep, blocked) 세 가지 상태로 구분됩니다.


	| 실행 | 프로세스가 CPU를 점유하고 명령을 수행중인 상태                        |
	| -- | -------------------------------------------------- |
	| 준비 | CPU만 할당받으면 즉시 명령을 수행할 수 있도록 준비된 상태                 |
	| 봉쇄 | CPU를 할당받아도 명령을 실행할 수 없는 상태 - ex. I/O 작업을 기다리는 경우 등 |



  </details>


---


---


### Q. ⭐⭐ Multi thread에 대해서 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


thread는 한 process 내에서 실행되는 **동작(기능 function)의 단위**입니다. 각 thread는 속해있는 process의 Stack 메모리를 제외한 나머지 memory 영역을 공유할 수 있습니다.


Multi thread란 하나의 process가 동시에 여러개의 일을 수행할수 있도록 해주는 것입니다. 즉, 하나의 process에서(실행이 된 하나의 program에서) 여러 작업을 병렬로 처리하기 위해 multi thread를 사용합니다. multi thread에서는 한 process 내에 여러 개의 thread가 있고, 각 thread들은 Stack 메모리를 제외한 나머지 영역(Code, Data, Heap) 영역을 공유하게 됩니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 thread는 process내에서 독립적인 기능을 수행합니다. 즉, 독립적으로 함수를 호출함을 의미하고 이를 위해 stack memory가 각자 필요한 거에요. thread가 무엇인지 이해하고, multi process와 어떤 점이 다른지를 생각해보면서 공부해보시길 바랍니다.  
> 또한, 독립적인 stack memory와 PC Register가 필요하다는 점을 잘 기억해주세요.


### Thread와 multi thread


thread는 process 내에서 *독립적인 기능*을 수행합니다. 각 thread가 *독립적인 기능*을 수행한다는 것은 *독립적으로 함수를 호출*함을 의미합니다.


[Multi_thread에_대해서_설명해주세요..m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1b6a0610-2cac-4a72-a1d0-e1770a2c66a9/Multi_thread%E1%84%8B%E1%85%A6_%E1%84%83%E1%85%A2%E1%84%92%E1%85%A2%E1%84%89%E1%85%A5_%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%E1%84%92%E1%85%A2%E1%84%8C%E1%85%AE%E1%84%89%E1%85%A6%E1%84%8B%E1%85%AD..m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T123017Z&X-Amz-Expires=3600&X-Amz-Signature=506c53a44ea5968feccb07710ee75be54860428749c802915a10f4391be2bb37&X-Amz-SignedHeaders=host&x-id=GetObject)


### Stack memory &  PC register


 thread가 함수를 호출하기 위해서는 인자 전달, Return Address 저장, 함수 내 지역변수 저장 등을 위한 독립적인 stack memory 공간을 필요로 합니다. 결과적으로 thread는 process로부터 Stack memory 영역은 독립적으로 할당받고, Code, Data, Heap 영역은 공유하는 형태를 갖게 됩니다. 


 또한 multi thread에서는 각각의 thread마다 PC register를 가지고 있어야 합니다. 그 이유는 한 process 내에서도 thread끼리 context switch가 일어나게 되는데, PC register에 code address가 저장되어 있어야 이어서 실행을 할 수 있기 때문입니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_35.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. thread는 왜 독립적인 stack memory영역이 필요한가요?


	**[핵심 답변]**


	Stack 영역은 함수 호출 시 전달되는 인자, 함수의 Return Address, 함수 내 지역변수 등을 저장하기 위한 memory 영역입니다. thread가 process내에서 "**독립적인 기능을 실행**”한다는 것은 "**독립적으로 함수를 호출**"함을 의미합니다. 따라서 각 thread가 독립적인 동작을 실행하기 위해서는 각 thread의 stack memory영역이 독립적이여야 합니다.


Q. process와 thread를 비교설명 해주세요.


	**[핵심 답변]**


	process는 운영체제로부터 자원을 할당받는 작업의 단위이고 thread는 process가 할당받은 자원을 이용하는 실행의 단위입니다. 즉, process는 실행파일(program)이 memory**에 적재**되어 **CPU를 할당**받아 **실행**되는 것입니다. thread는 **한** process **내**에서 실행되는 **동작의 단위**입니다. 


	process는 memory공간에 code, data, heap, stack영역이 있는데, thread는 process내에서 stack영역을 제외한 code, data, heap영역을 공유합니다.



  </details>


---


---


### Q. ⭐⭐ multi process와 multi thread를 비교설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>

- multi thread는 multi process보다 적은 메모리 공간을 차지하고 `Context Switching`이 빠릅니다.
- multi process는 multi thread보다 많은 메모리공간과 CPU 시간을 차지합니다.
- multi thread는 동기화 문제와 하나의 thread 장애로 전체 thread가 종료될 위험이 있습니다.
- multi process는 하나의 process가 죽더라도 다른 process에 영향을 주지 않아 안정성이 높습니다.


  </details>


<details>
  <summary>[면접 </summary>


> 💡 두 방법은 동시에 여러 작업을 수행한다는 측면에서 유사한 면이 있습니다. 적용할 시스템에 따라 두 방법의 장단점을 고려하여 적합한 방식을 선택해야 합니다.  
> 메모리 구분이 필 요할 때는 multi process가 유리합니다. 반면에 Context switching이 자주 일어고 데이터 공유가 빈번한 경우, 그리고 자원을 효율적으로 사용해야 되는 경우에는 multi thread를 사용하는 것이 유리합니다.  
> 비교하여 설명하라는 면접 질문이 나오면 위에 적어드린 내용 안에서 설명을 하시면 됩니다.


### Multi process & Multi thread


multi process대신 multi thread로 구현할 경우, 메모리 공간과 시스템 자원 소모가 줄어들게 됩니다. 하지만 multi thread를 사용할 때는 thread간 자원을 공유하기 때문에 동기화문제가 발생할 수 있기 때문에 이를 고려한 프로그램 설계가 필요합니다.


또한 process간의 통신(IPC)보다 thread간의 통신 비용이 적기 때문에 통신으로 인한 오버헤드가 적습니다.


|               | 메모리 사용 / CPU 시간           | Context switching | 안정성 |
| ------------- | ------------------------- | ----------------- | --- |
| multi process | 많은 **메모리 공간 / CPU 시간** 차지 | 느림                | 높음  |
| multi thread  | 적은 **메모리 공간 / CPU 시간** 차지 | 빠름                | 낮음  |


[multi_process와_Multi_thread를_비교_설명해_주세요..m4v](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/cb646ae2-e505-46c1-b395-a68b9d7443a4/multi_process%E1%84%8B%E1%85%AA_Multi_thread%E1%84%85%E1%85%B3%E1%86%AF_%E1%84%87%E1%85%B5%E1%84%80%E1%85%AD_%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%E1%84%92%E1%85%A2_%E1%84%8C%E1%85%AE%E1%84%89%E1%85%A6%E1%84%8B%E1%85%AD..m4v?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230518%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230518T123020Z&X-Amz-Expires=3600&X-Amz-Signature=e6b7c945cee9c2ee27ff2521e916621ea6ce575f8ab190da85221390b754bdfb&X-Amz-SignedHeaders=host&x-id=GetObject)


⁉️ [참고자료] chrome과 firefox의 차이(multi process vs multi thread)


[bookmark](https://levelup.gitconnected.com/how-web-browsers-use-processes-and-threads-9f8f8fa23371)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. multi thread가 multi process보다 좋은 점은 무엇인가요?


	**[핵심 답변]**


	multi process를 이용하던 작업을 multi thread로 구현할 경우, 메모리 공간과 시스템 자원 소모가 줄어들게 됩니다. 또한 process를 생성하고 자원을 할당하는 등의 system call을 생략할 수 있기 때문에 자원을 효율적으로 관리할 수 있습니다. 뿐만 아니라 Context switching 시 캐시 메모리를 초기화할 필요가 없어서 속도가 빠릅니다.


	데이터를 주고 받을 때를 비교해보면, process 간의 통신(IPC)보다 multi thread 간의 통신 비용이 적기 때문에 통신으로 인한 오버헤드가 적습니다. 


Q. multi thread가 multi process보다 안좋은 점은 무엇인가요?


	**[핵심 답변]**


	thread 간의 자원 공유 시 동기화문제가 발생할 수 있어서 프로그램 설계 시 주의가 필요하고, 하나의 thread에 문제가 생기면 process내의 다른 thread에도 문제가 생길 수 있습니다.



  </details>


---


---


### Q. ⭐⭐ multi process환경에서 process간에 데이터를 어떻게 주고 받을까요?


<details>
  <summary>[핵심 답변]</summary>


원칙적으로 process는 독립적인 주소 공간을 갖기 때문에, 다른 process의 주소 공간을 참조할 수 없습니다. 하지만 경우에 따라 운영체제는 process 간의 자원 접근을 위한 매커니즘인 프로세스 간 통신(IPC, Inter Process Communication)를 제공합니다.


프로세스 간 통신(IPC) 방법으로는 파이프, 파일, 소켓, 공유메모리 등을 이용한 방법이 있습니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 IPC는 면접에서도 굉장히 자주 나오는 질문 입니다. multi thread와 다르게 process끼리는 데이터 공유를 하고 있지 않습니다. 따라서 데이터를 주고 받기 위해서 IPC기법을 사용합니다. IPC는 크게 공유메모리 방식과 메시지 전달방식으로 나뉘는데 이 둘의 장단점과 차이점을 중심으로 공부해가시길 바랍니다.


### IPC (Inter-Process Communication)


 process는 각자 자신만의 독립적인 주소공간을 가지는데, 다른 process가 이 주소공간을 참조하는 것은 허용하지 않습니다. 그렇기 때문에 다른 process와 데이터를 주고받을 수 없습니다. 이를 해결하고자 운영체제는 IPC기법을 통해 process들 간에 통신을 가능하게 해줍니다.


 process간 통신(IPC)에는 기본적으로 <span style="background-color: #FBF3DB">**공유메모리(shared memory)**</span>와 <span style="background-color: #FBF3DB">**메시지 전달(message passing)**</span>의 두 가지 모델이 있습니다. 


### 공유메모리(shared memory)


 공유 메모리 방식에서는 process들이 주소 공간의 일부를 공유합니다. 공유한 메모리 영역에 읽기/쓰기를 통해서 통신을 수행합니다. process가 공유 메모리 할당을 kernel에 요청하면 kernel은 해당 process에 메모리 공간을 할당해줍니다. 공유 메모리 영역이 구축된 이후에는 모든 접근이 일반적인 메모리 접근으로 취급되기 때문에 더이상 kernel의 도움없이도 각 process들이 해당 메모리 영역에 접근할 수 있습니다. 따라서 커널의 관여 없이 데이터를 통신할 수 있기 때문에 IPC<span style="background-color: #FBF3DB">속도가 빠르다</span>는 장점이 있습니다.


 공유 메모리 방식은 process간의 통신을 수월하게 만들지만 동시에 같은 메모리 위치에 접근하게 되면 <span style="background-color: #FBF3DB">일관성 문제</span>가 발생할 수 있습니다. 이에 대해서는 커널이 관여하지 않기 때문에 process들 끼리 직접 공유 메모리 접근에 대한 동기화 문제를 책임져야 합니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_36.png)


### 메시지 전달(message passing)


메시지 전달 방법은 통상 system call을 사용하여 구현됩니다. kernel을 통해 send(message)와 receive(message)라는 두 가지 연산을 제공받습니다. 예를 들면, process1이 kernel로 message를 보내면 kernel이 process2에게 message를 보내주는 방식으로 동작합니다. 


 메모리 공유보다는 속도가 느리지만, <span style="background-color: #FBF3DB">충돌을 회피할 필요가 없기</span> 때문에 적은양의 데이터를 교환하는 데 유용합니다. 또, 구현하기가 쉽다는 장점이 있습니다. 


 대표적인 예시로는 pipe, socket, message queue등이 있습니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_37.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. IPC의 예시를 들어주실 수 있나요?


	**[핵심 답변]**


	 IPC는 크게 공유 메모리 모델과 메시지 전달 모델로 나눌 수 있습니다. 공유 메모리 모델은 주소 공간의 일부를 공유하며 공유한 메모리 영역에 read/write를 통해 통신하게 되는데, 예시로는 공유메모리와 POSIX가 있습니다. 메시지 전송 모델의 경우에는 kernel을 통해 send/receive 연산을 통해 데이터를 전송합니다. 예시로는 Pipe, socket, message queue 등이 있습니다.


Q. 공유메모리와 메시지 전달 모델의 장단점을 설명해 주세요.


	**[핵심 답변]**


	 공유 메모리 모델은 초기에 공유 메모리 할당을 제외하면 kernel의 관여 없이 통신할 수 있기 때문에 속도가 빠른 장점있습니다. 하지만 여러 process가 동시에 메모리에 접근하는 문제가 발생할 수 있어서 별도의 동기화 과정이 필요하다는 단점이 있습니다. 


	 메세지 전달 모델은 kernel을 통해서 데이터를 주고받기 때문에 통신 속도가 느리다는 단점이 있습니다. kernel에서 제어를 해주기 때문에 안전하며 kernel이 동기화를 제공해준다는 장점이 있습니다.



  </details>


---


---


###  Q. ⭐ Multi process/thread 환경에서 동기화 문제를 어떻게 해결하나요?


<details>
  <summary>[핵심 답변]</summary>


동기화문제를 해결하기 위해 mutex, semaphore 기법 등을 사용할 수 있습니다.


Mutex란 1개의 스레드만이 공유 자원에 접근할 수 있도록 하여, 경쟁 상황(race condition)를 방지하는 기법입니다. 공유 자원을 점유하는 thread가 lock을 걸면, 다른 thread는 unlock 상태가 될 때까지 해당 자원에 접근할 수 없습니다.


Semaphore란 S개의 thread만이 공유 자원에 접근할 수 있도록 제어하는 동기화 기법입니다. Semaphore 기법에서는 정수형 변수 S(세마포) 값을 가용한 자원의 수로 초기화하고, 자원에 접근할 때는 `S--` 연산을 수행하여 세마포 값을 감소시키고 자원을 방출할 때는 `S++` 연산을 수행하여 세마포 값을 증가시킵니다. 이 때 세마포 값이 0이 되면 모든 자원이 사용 중임을 의미하고, 이후 자원을 사용하려는 프로세스는 세마포 값이 0보다 커질 때까지 block 됩니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 mutex와 semaphore는 면접 질문에서 자주 나오는 용어입니다. 이를 설명하기 위해서는 동기화 문제가 무엇이고 왜 발생하는지에 대해서 설명을 할줄 알아야 합니다. multi process/thread  환경에서는 서로 다른 thread가 메모리 영역을 공유하기 때문에 여러 thread가 동일한 자원에 동시에 접근하여 엉뚱한 값을 읽거나 수정하게 되는 동기화 문제가 발생할 수 있습니다. 더 잘 이해하기 위해 atomic operation과 경쟁상황을 살펴보시기 바랍니다.  
> 동기화 문제를 해결하기 위해 임계영역을 설정하고, mutex와 semaphore 기법을 사용합니다. 각 기법의 특징을 중심으로 답변을 하시면 됩니다.


### 동기화 문제


동기화 문제란 서로 다른 thread가 메모리 영역을 공유하기 때문에 여러 thread가 **동일한 자원에 동시에 접근**하여 엉뚱한 값을 읽거나 수정하는 문제입니다.


예시를 통해 알아보겠습니다.


`count++`를 CPU 입장에서 분해해보면 3개의 atomic operations으로 나뉩니다.

1. `count` 변수의 값을 가져온다.
2. `count` 변수의 값을 1 증가시킨다.
3. 변경된 `count` 값을 저장한다.

CPU는 atomic operation을 연산하게 됩니다. 따라서 `count++`을 하기 위해 3번의 연산을 하게 됩니다.


 시분할 시스템으로 작동하는 multi process/multi thread 시스템에서, 두 개의 thread가 동일한 데이터인 `count`에 동시에 접근을 하여 조작을 하는 상황을 가정해보겠습니다. thread1에서도 `count++`를 하고, thread2에서도 `count++`를 한다면 그 실행 결과가 접근이 발생한 순서에 따라 달라질 수 있습니다. 이를 경쟁상황(race condition)이라고 합니다. 


즉, 둘 이상의 thread가 동일한 자원에 접근하여 조작하고, 그 실행 결과가 접근이 발생한 순서에 따라 달라지는 경쟁상황에 의해서 동기화 문제가 발생할 수 있습니다. 경쟁 상황으로부터 보호하기 위해, 우리는 한 순간에 하나의 process/thread만 해당 자원에 접근하고 조작할 수 있도록 보장해야 합니다. 다시 말해서 process/thread들이 동기화되도록 할 필요가 있습니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_38.png)


### 임계영역(critical section)


둘 이상의 process/thread가 동시에 동일한 자원에 접근하도록 하는 프로그램 코드 부분을 의미합니다. 중요한 특징중 하나는, 한 process/thread가 자신의 임계구역에서 수행하는 동안에는 다른 process/thread들은 그들의 임계구역에 들어갈 수 없어야 한다는 사실 입니다. 즉, 임계영역 내의 코드는 원자적으로(atomically) 실행이 되어야 합니다.


 원자적으로 실행 되기 위해서 각각의 process/thread는 자신의 임계구역으로 진입하려면 진입 허가를 요청해야합니다. 이 부분을 entry section이라고 하고, 진입이 허가되면 임계영역을 실행할 수 있습니다. 임계영역이 끝나고 나면 exit section으로 퇴출을 하게 됩니다. 임계영역의 원자성을 보장하여 process/thread들이 동기화되도록 할 수 있습니다.


 동기화 방법은 대표적으로 Mutex와 Semaphore가 있습니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_39.png)


### Mutex


동기화 방법중 하나로 mutual exclusion의 축약어 입니다. 공유자원에 접근할 수 있는 process/thread의 수를 1개로 제한합니다. 임계영역을 보호하고, 경쟁상황을 방지하기 위해 mutex lock을 사용합니다. 즉 process/thread는 임계영역에 들어가기 전에 반드시 lock을 획득해야 하고, 임계구역을 빠져나올 때 lock을 반환해야 합니다. 


acquire()함수가 lock을 획득하고 release()함수가 lock을 반환합니다.


```c++
acquire() // entry section

// critical section

release() // exit section
```


busy waiting은 다른 process/thread가 생상적으로 사용할 수 있는 CPU를 낭비한다는 단점이 있습니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_40.png)


### Semaphore


  동기화 방법중 하나로, mutex와 가장 큰 차이점은 공유 자원에 접근할 수 있는 process/thread의 개수가 2개 이상이 될 수 있다는 것입니다.


 semaphore 변수 S(세마포)에 동시에 접근 가능한 process/thread의 갯수를 저장합니다. S가 0보다 크면 임계영역으로 들어갈 수 있고, 임계영역에 들어가면 S값을 1 감소시킵니다. S값이 0이 되면 다른 process/thread는 임계영역으로 접근할 수 없습니다. 임계영역에서의 작업이 끝나고 임계영역에서 exit하면서 S값을 1 증가시킵니다. 


```c++
wait(S) // entry section

// critical section

signal(S) // exit section
```


semaphore값이 0,1만 가질 수 있는 경우 binary semaphore라고 하는데, 이는 mutex랑 거의 유사하게 작동합니다. 


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_41.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. mutex와 semaphore 기법을 비교 설명해 주세요.


	**[핵심 답변]**


	 mutex는 오직 1개의 process/thread만이 공유 자원에 접근할 수 있고, semaphore는 세마포 변수의 값만큼의 process/thread들이 동시에 자원에 접근할 수 있습니다. mutex는 binary semaphore라고 할 수 있습니다.



  </details>


---


---


### Q. 교착상태(Deadlock)에 대해서 간단히 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


둘 이상의 thread가 각기 다른 thread가 점유하고 있는 자원을 서로 기다릴 때, 무한 대기에 빠지는 상황을 말합니다.


 deadlock이 발생하는 조건은 상호 배제(mutual exclusion), 점유 대기(hold-and-wait), 비선점(no preemption), 순환 대기(circular wait)입니다. 이 4가지 조건이 동시에 성립할 때 발생할 수 있습니다. 


 deadlock 문제를 해결하는 방법에는 무시, 예방, 회피, 탐지-회복의 4가지 방법이 있습니다



  </details>


<details>
  <summary>[면접 </summary>


> 💡 면접에서 deadlock 질문이 나온다면, deadlock이 발생하기 위한 조건과 해결방법을 묻는 것입니다.   
> deadlock이 발생하는 조건은 상호배제, 점유대기, 비선점, 순환대기 4가지 이고, 이를 해결하는 방법은 무시, 예방, 회피, 탐지-회복 4가지 입니다.


### Deadlock 예시


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_42.png)


### Deadlock 발생 조건


deadlock은 다음 4가지 조건이 동시에 성립할 때 발생할 수 있습니다.

1. **상호 배제**(mutual exclusion)
	- 동시에 한 thread만 자원을 점유할 수 있는 상황입니다.
	- 다른 thread가 자원을 사용하려면 자원이 방출될 때까지 기다려야 합니다.
2. **점유 대기**(hold-and-wait)
	- thread가 자원을 보유한 상태에서 다른 thread가 보유한 자원을 추가로 기다리는 상황입니다.
3. **비선점**(no preemption)
	- 다른 thread가 사용 중인 자원을 강제로 선점할 수 없는 상황입니다.
	- 자원을 점유하고 있는 thread에 의해서만 자원이 방출됩니다.
4. **순환 대기**(circular wait)
	- 대기 중인 thread들이 순환 형태로 자원을 대기하고 있는 상황입니다.

### Deadlock 해결 방법


deadlock 문제를 해결하는 방법에는 (1) 무시, (2) 예방, (3) 회피, (4) 탐지-회복의 4가지 방법이 있습니다.


| 기법    | 설명                                                                 | 비고                                                                                                              |
| ----- | ------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------- |
| 무시    | deadlock 발생 확률이 낮은 시스템에서 아무런 조치도 취하지 않고 deadlock을 무시하는 방법          | - 무시 기법은 **시스템 성능 저하가 없다**는 큰 장점이 있습니다.
- 현대 시스템에서는 deadlock이 **잘 발생하지 않고**, **해결 비용이 크기 때문에** 무시 방법이 많이 사용됩니다. |
| 예방    | 교착 상태의 4가지 발생 조건중 하나가 성립하지 않게 하는 방법                                | - 순환 대기 조건이 성립하지 않도록 하는 것이 현실적으로 가능한 예방 기법입니다.
- 자원 사용의 **효율성이 떨어지고 비용이 큽**니다.                                  |
| 회피    | thread가 앞으로 자원을 어떻게 요청할지에 대한 정보를 통해 순환 대기 상태가 발생하지 않도록 자원을 할당하는 방법 | - 자원 할당 그래프 알고리즘, 은행원 알고리즘 등을 사용하여 자원을 할당하여 deadlock을 회피합니다.                                                    |
| 탐지-회복 | 시스템 검사를 통해 deadlock 발생을 탐지하고, 이를 회복시키는 방법                          | - 자원 사용의 **효율성이 떨어지고 비용이 큽**니다.                                                                                 |



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. deadlock은 언제 발생하게 되나요?


	**[핵심 답변]**


	deadlock은 상호 배제(mutual exclusion), 점유 대기(hold-and-wait), 비선점(no preemption), 순환 대기(circular wait)의 4가지 조건이 **동시에 성립**할 때 발생할 수 있습니다.


	상호 배제는 동시에 한 thread만 자원을 점유할 수 있는 상황이고, 점유 대기는 thread가 자원을 보유한 상태에서 다른 thread가 보유한 자원을 추가적으로 기다리는 상황입니다. 또 비선점은 다른 thread가 사용 중인 자원을 강제로 선점할 수 없는 상황을 뜻하고, 순환 대기는 대기 중인 thread들이 순환 형태로 자원을 대기하는 상황을 말합니다.



  </details>


---


## Memory


---


### Q. paging이란 뭔가요?


<details>
  <summary>[핵심 답변]</summary>


paging이란 process가 할당받은 메모리 공간을 일정한 <span style="background-color: #FBF3DB">page 단위</span>로 나누어, 물리 메모리에서 연속되지 않는 <span style="background-color: #FBF3DB">서로 다른 위치</span>에 저장하는 메모리 관리 기법입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 면접에서 자주나오진 않지만, 중요한 내용들이 많이 있어서 알아두면 깊이있는 질문이 나올 때 잘 답변을 하실 수 있습니다.   
> 특히 논리적주소와 물리적주소의 차이를 이해해야하고, 물리 메모리의 연속되지 않는 서로 다른 위치에 page단위만큼 저장한다는 점을 설명할 수 있어야 합니다.


> **[용어정리]** - 논리적 주소(logical address)란?


	process가 memory에 적재되기 위한 독자적인 주소 공간인 논리적 주소(logical address)가 생성됩니다. 논리적 주소는 각 process마다 독립적으로 할당되며, 0번지부터 시작됩니다.


> **[용어정리]** - 물리적 주소(physical address)란?


	물리적 주소(physical address)는 process가 실제로 메모리에 적재되는 위치를 말합니다.


> **[용어정리]** - 주소 바인딩(address binding)이란?


	CPU가 기계어 명령을 수행하기 위해 process**의 논리적 주소가 실제 물리적 메모리의 어느 위치에 매핑되는지 확인하는 과정**을 주소 바인딩(address binding)이라고 합니다.


### Paging


paging 기법은 process의 메모리 공간을 동일한 크기의 page 단위로 나누어 물리적 메모리의 서로 다른 위치에 page들을 저장하는 메모리 관리 기법입니다. paging 기법에서는 물리적 메모리를 **page와 같은 크기의 frame**으로 미리 나누어둡니다.


paging 기법에서는 주소 바인딩(address binding)을 위해 모든 프로세스가 각각의 주소 변환을 위한 page table을 갖습니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_43.png)


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_44.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. paging 기법 사용시 발생할 수 있는 **메모리 단편화(Memory fragmentation)** 문제에 대해 설명하시오


	**[핵심 답변]**


	 물리적 메모리 공간이 작은 조각으로 나눠져서 메모리가 충분히 존재함에도 할당이 불가능한 상태를 보고 메모리 단편화가 발생했다고 말합니다.


	 paging 기법에서는 process의 논리적 주소 공간과 물리적 메모리가 같은 크기의 page 단위로 나누어지기 때문에 외부 단편화 문제가 발생하지 않습니다. 하지만 process 주소 공간의 크기가 page 크기의 배수라는 보장이 없기 때문에, 프로세스의 주소 공간 중 가장 마지막에 위치한 page에서는 내부 단편화 문제가 발생할 가능성이 있습니다.



  </details>


---


---


### Q. segmentation에 대해서 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>


segmentation이란 process가 할당받은 메모리 공간을 <span style="background-color: #FBF3DB">논리적 의미 단위(segment)</span>로 나누어, <span style="background-color: #FBF3DB">연속되지 않는 물리 메모리 공간에 할당</span>될 수 있도록 하는 메모리 관리 기법입니다.



  </details>


<details>
  <summary>[면접 </summary>


> 💡 page와 같이 면접에 자주나오진 않지만, 메모리에 대해서 이해하는데 중요한 내용이 많이 담겨져 있기 때문에 알아두시면 좋습니다.   
> 일정한 크기의 단위로 나누어 할당을 했던 page와 다르게, segmentation은 의미 단위로 물리 메모리에 할당을 하는 기법임을 설명할 수 있어야 합니다. 특히 code, data, heap, stack등의 기능(의미)단위로 나눈다는 점을 기억하시길 바랍니다.


### Segmentation


segmentation 기법은 process가 할당받은 메모리 공간을 **논리적 의미 단위(segment)**로 나누어, 연속되지 않는 물리 메모리 공간에 할당될 수 있도록 하는 메모리 관리 기법입니다.


일반적으로 process의 메모리 영역 중 <span style="background-color: #FBF3DB">Code, Data, Heap, Stack 등의 기능 단위로 segment를 정의</span>하는 경우가 많습니다.


segmentation 기법에서는 주소 바인딩(address binding)을 위해 모든 프로세스가 각각의 주소 변환을 위한 segment table을 갖습니다.


![](https://raw.githubusercontent.com/encoreKwang/PullRequestTest/master/categoryNameTEST2/imgs/CS%20%EC%A0%95%EB%A6%AC%20(1)_20230518-21%3A30%3A44_45.png)



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>


Q. segmentation의 **메모리 단편화(Memory fragmentation)** 문제에 대해 설명해 주세요.


	**[핵심 답변]**


	segmentation 기법에서 segment의 크기만큼 메모리를 할당하므로 내부 단편화 문제가 발생하지 않습니다. 하지만 서로 다른 크기의 segment들이 메모리에 적재되고 제거되는 일이 반복되면, 외부 단편화 문제가 발생할 가능성이 있습니다.


Q. paging과 segmentation의 차이는 뭔가요?


	 paging은 일정한 크기의 단위로 나누어 할당을 하는데, 이에 반해 segmentation은 code, data, heap, stack등의 기능(의미)단위로 물리 메모리에 할당을 하는 기법입니다. 


	 paging의 경우 내단편화의 문제가 발생할 수 있는데, 이에 반해 segmentation은 외단편화의 문제가 발생할 수 있습니다.


Q. paged segmentation 기법에 대해 설명하시오



  </details>


---


---


### Q. ⭐ 가상 메모리에 대해서 설명해 주세요.


<details>
  <summary>[핵심 답변]</summary>



  </details>


<details>
  <summary>[면접 </summary>



  </details>


<details>
  <summary>[꼬꼬무 문답]</summary>



  </details>


---


세마포어의 한계점
s++ s-- 락을 가지고 있으면 하나의 스레드가 기다려야하는데
계속 기다리니까 cpu를 쓰니까 busywaiting을 발생
해결법은 block and wait 방식이 있다.
자원이 없거나 기다리는 경우 sleep
자원을 할당받을 수 있으면 wake up


[https://choiblack.tistory.com/23](https://choiblack.tistory.com/23)


atomic 싱크로나이즈


[데이터베이스](66231727-a1e9-4b52-bbb4-f25e6ceb90bf)


[네트워크](23438539-a616-41c7-8aff-4c85d6fe0313)


[모의면접](37dbcc13-cc21-44aa-8588-77d5ece4ea3c)


[CS](d1ddd642-b635-43af-b362-5a8b3269b729)


[티맥스핀테크CS질문](2f49f143-8393-4c45-a477-9a0a17e758d8)

